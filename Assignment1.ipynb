{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgGc4qaTjPrU"
      },
      "source": [
        "Welcome to aasignment 1.                                                       \n",
        "\n",
        "We are using pathology images for our first assignment please download data from this link https://drive.google.com/drive/folders/10dUOzcPR-PQwfFYcHk5gsLjIjSorQ32Q?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s4K2S-dhTnF"
      },
      "source": [
        "\n",
        "\n",
        "# Task 1: Feature Generation (15%)\n",
        "# Use and run the following code (a deep network) to generate features from a set of training images. For this assignment, you do not need to know how the deep network is working here to extract features.\n",
        "# This code extracts the features of image T4.tif (in the T folder of dataset). Modify the code so that it iterates over all images of the dataset and extracts their features.\n",
        "# Allocate 10% of the data for validation.\n",
        "\n",
        "# Insert your code here for Task 1\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "94c_H8Yv7IDs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/Sofiane/Applications/anaconda3/envs/DLenv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Users/Sofiane/Applications/anaconda3/envs/DLenv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features shape: (780, 1024)\n",
            "Image labels shape: (780,)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import densenet121\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Load pre-trained DenseNet model\n",
        "model = densenet121(pretrained=True)\n",
        "\n",
        "# Remove the classification layer (last fully connected layer)\n",
        "model = torch.nn.Sequential(*list(model.children())[:-1])\n",
        "\n",
        "# Add a global average pooling layer\n",
        "model.add_module('global_avg_pool', torch.nn.AdaptiveAvgPool2d(1))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Define the image preprocessing pipeline\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Set the path to the dataset folder\n",
        "dataset_folder = \"data\"\n",
        "\n",
        "features_list = list()\n",
        "labels_list = list()\n",
        "\n",
        "# Iterate over each subfolder (A to T)\n",
        "# Subfolder A = label 1, B = label 2, etc. \n",
        "for label, subfolder in enumerate(sorted(os.listdir(dataset_folder))):\n",
        "    subfolder_path = os.path.join(dataset_folder, subfolder)\n",
        "\n",
        "    # Check if it is a directory\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        # List all image files in the subfolder\n",
        "        image_files = [f for f in os.listdir(subfolder_path) if f.endswith('.tif')]\n",
        "\n",
        "        # Iterate over each image in the subfolder\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(subfolder_path, image_file)\n",
        "\n",
        "            image = Image.open(image_path)\n",
        "            input_tensor = preprocess(image)\n",
        "            input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension\n",
        "            input_var = Variable(input_batch)\n",
        "\n",
        "            # Forward pass through the model\n",
        "            features = model(input_var)\n",
        "            feature_vector = features.squeeze().detach().numpy()\n",
        "\n",
        "            # Append the feature vector and label to the lists\n",
        "            features_list.append(feature_vector)\n",
        "            labels_list.append(label)\n",
        "        \n",
        "\n",
        "features_array = np.array(features_list)\n",
        "labels_array = np.array(labels_list)\n",
        "\n",
        "# Save features and labels\n",
        "np.save(file=\"image_features.npy\", arr=features_array)\n",
        "np.save(file=\"image_labels.npy\", arr=labels_array)\n",
        "\n",
        "print(\"Image features shape:\", features_array.shape)  # shape (Number of images, Features dim)\n",
        "print(\"Image labels shape:\", labels_array.shape)  # shape (Number of images,) i.e one label per image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set shapes: (624, 1024) (624,)\n",
            "Validation set shapes: (78, 1024) (78,)\n",
            "Test set shapes: (78, 1024) (78,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Split ratio (Train, Valid, Test) 80:10:10\n",
        "\n",
        "features_array = np.load(\"image_features.npy\")\n",
        "labels_array = np.load(\"image_labels.npy\")\n",
        "\n",
        "features_train, features_temp, labels_train, labels_temp = train_test_split(\n",
        "    features_array, labels_array, test_size=0.2, random_state=42)\n",
        "\n",
        "features_valid, features_test, labels_valid, labels_test = train_test_split(\n",
        "    features_temp, labels_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting arrays\n",
        "print(\"Training set shapes:\", features_train.shape, labels_train.shape)\n",
        "print(\"Validation set shapes:\", features_valid.shape, labels_valid.shape)\n",
        "print(\"Test set shapes:\", features_test.shape, labels_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DguMbSShmHT"
      },
      "source": [
        "# Task 2: High Bias Classification Method (5%)\n",
        "# Choose a classification method and let is have a high bias.\n",
        "# Train it on the generated features and discuss why it is underfitting.\n",
        "\n",
        "# Insert your code here for Task 2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xG7aIh1lhpW3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR8MxxoGhpxF"
      },
      "source": [
        "# Task 3: High Variance Classification Method (5%)\n",
        "# Use the chosen classification method and let it have a high variance.\n",
        "# Train it on the generated features and discuss why it is overfitting.\n",
        "\n",
        "# Insert your code here for Task 3\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrsSDN_7huYB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzxSVPWXht-m"
      },
      "source": [
        "# Task 4: Balanced Classification Method (15%)\n",
        "# Use the chosen classification method and let it balance the bias and variance.\n",
        "# Train it on the generated features, possibly adjusting parameters.\n",
        "# Discuss insights into achieving balance.\n",
        "\n",
        "# Insert your code here for Task 4\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjgmSxk7h7vZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKRG3PfFh8Ot"
      },
      "source": [
        "# Task 5: K-Means Clustering (20%)\n",
        "# Apply K-Means clustering on the generated features.\n",
        "# Test with available labels and report accuracy.\n",
        "# Experiment with automated K and compare with manually set 20 clusters.\n",
        "\n",
        "# Insert your code here for Task 5\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VLuOkJyAh-mN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/Sofiane/Applications/anaconda3/envs/DLenv/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([ 0, 18,  5, 17,  3,  4,  6,  2, 19,  4, 14, 16,  3, 16, 16,  2,  3,\n",
              "       17, 11, 17,  3, 15, 14,  3,  4, 16,  1,  7,  7,  0,  5, 13, 12, 17,\n",
              "       15, 10,  6, 16,  3,  3,  8,  5,  5,  2, 14,  4, 14,  6,  1,  2,  0,\n",
              "        0,  9,  7,  3,  1, 18, 19,  1,  4,  4, 11, 19,  3, 11,  8,  6, 11,\n",
              "       15,  3, 16, 13,  3, 11,  0, 15, 12,  3], dtype=int32)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=20)\n",
        "\n",
        "# TODO: fit predict on train features and plot in 2D using tSNE to visualize pattern from the features space\n",
        "kmeans.fit(features_train)\n",
        "kmeans.predict(features_valid) # clusters predictions on validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43sPfI7Jh-9p"
      },
      "source": [
        "# Task 6: Additional Clustering Algorithm (10%)\n",
        "# Choose another clustering algorithm and apply it on the features.\n",
        "# Test accuracy with available labels.\n",
        "\n",
        "# Insert your code here for Task 6\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn9f41LWiCDr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fPfoBsaiCXu"
      },
      "source": [
        "# Task 7: PCA for Classification Improvement (20%)\n",
        "# Apply PCA on the features and then feed them to the best classification method in the above tasks.\n",
        "# Assess if PCA improves outcomes and discuss the results.\n",
        "\n",
        "# Insert your code here for Task 7\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoOFXhdmiHeD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQqNra7eiHx-"
      },
      "source": [
        "# Task 8: Visualization and Analysis (10%)\n",
        "# Plot the features in a lower dimension using dimentinality reduction techniques.\n",
        "# Analyze the visual representation, identifying patterns or insights.\n",
        "\n",
        "# Insert your code here for Task 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1npTL_NkjNdL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
